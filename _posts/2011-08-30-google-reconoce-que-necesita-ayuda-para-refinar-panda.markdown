--- 
layout: post
title: "Google reconoce que necesita ayuda para refinar Panda"
permalink: /2011/08/30/google-reconoce-que-necesita-ayuda-para-refinar-panda/index.html
author: Jorge Grippo
date: 2011-08-30 15:46:12
comments: true
sharing: true
footer: true
status: publish
type: post
published: true
categories: 
- Noticias

---
<!-- 231 -->
Hace un par de días, <a href="https://twitter.com/#!/mattcutts/status/107141110262013952">Matt Cutts</a> pedía colaboración para mejorar los resultados de Google:

<img class="aligncenter" src="https://searchengineland.com/figz/wp-content/seloads/2011/08/cutts-tweet.jpg" alt="" width="531" height="192" />

Por medio del formulario provisto en la siguiente url, se solicita denunciar a <a href="https://en.wikipedia.org/wiki/Scraper_site">Scrapers</a>:

<a href="https://docs.google.com/spreadsheet/viewform?formkey=dGM4TXhIOFd3c1hZR2NHUDN1NmllU0E6MQ&amp;ndplr=1">https://docs.google.com/spreadsheet/viewform?formkey=dGM4TXhIOFd3c1hZR2NHUDN1NmllU0E6MQ&amp;ndplr=1</a>

En un <a href="https://www.webmasterworld.com/google/4355698.htm">hilo al respecto en WMW</a>, se muestra una <a href="https://www.google.com/support/forum/p/Webmasters/thread?tid=21e50ed1333526fc&amp;hl=es">interesante intervención</a> del <a href="https://www.google.com/support/forum/p/Webmasters/user?userid=09847171557269856014&amp;hl=en">empleado de Google Wyzs</a>, donde este último explica con cierto detalle de análisis textual, por qué penalizó al <a href="https://www.google.com/support/forum/p/Webmasters/user?userid=00368669713783370904&amp;hl=en">webmaster Benjy M.</a> con un "-50 penalty" a su red de 30 sitios. Resulta ser que no solo copy+paste es panlizado, sino también el refraseo o "refritado" de textos, como es el caso de la nota que se analiza, donde no hay igualdad comparativa del texto con algún otro considerado original, sino ciertas frases concidentes en varios párrafos, aparecidas en el mismo orden que en el original.

El ánimo de los webmasters está bastante caldeado. El venerado Brett Tabke, fundador de WMW, tuvo que eliminar una decena de comentarios muy ácidos en este hilo. Algunos de los que sobrevivieron a la tijera de Brett, aconsejan a Google investigar en sus propiedades Blogger, App Engine y Adsense, para encontrar a todos los scrapers, sin necesidad de pedir colaboración al público. Otros señalan que el formulario no está bien diseñado para reportar sitios de a cientos, ya que tomarían mucho tiempo hacerlo uno por uno.

Conclusión: la lucha contra scrapers ha mostrado un límite del todopoderoso equipo que desarrolla y mantiene el buscador Google. Simplemente no han podido desarrollar un motor 100% algorítmico, que no sea manipulable por scrapers. Por el momento. Por que con el aporte de los cerebrillos de quienes llenen dicho formulario, algún día lo lograrán.



